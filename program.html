<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="shortcut icon" href="../../assets/ico/favicon.ico">

    <title>Workshop on Scholarly Web Mining - Program</title>

    <!-- Bootstrap core CSS -->
    <link href="./dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy this line! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Custom styles for this template -->
    <link href="rrcf2014.css" rel="stylesheet">
  </head>
<!-- NAVBAR
================================================== -->
  <body>
    <div class="navbar-wrapper">
      <div class="container">

        <div class="navbar navbar-inverse navbar-static-top" role="navigation">
          <div class="container">

            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              	<a class="brand" href="index.html"> <img src="images/swm.png" alt="SWM2017"></a>
            </div>

            <div class="navbar-collapse collapse pull-right">
              <ul class="nav navbar-nav">
                <li><a href="index.html">Home</a></li>
                  <li><a href="http://www.wsdm-conference.org/2017/venue/">Venue</a></li>
                <li><a href="index.html#important-dates">Important Dates</a></li>
                <li class="dropdown active">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Information<b class="caret"></b></a>
                    <ul class="dropdown-menu">
                        <li><a href="cfp.html">Call for Papers</a></li>
                        <li><a href="invitedtalks.html">Invited talks</a></li>
                        <li><a href="program.html">Program</a></li>
                    </ul>
                </li>
                <li class="dropdown">
          			<a href="#" class="dropdown-toggle" data-toggle="dropdown">Committees<b class="caret"></b></a>
          			<ul class="dropdown-menu">
            			<li><a href="organizingcommittee.html">Organizing Committee</a></li>
            			<li><a href="programcommittee.html">Program Committee</a></li>
            		</ul>
        		</li>
                <li><a href="index.html#contact">Contact</a></li>
              </ul>
            </div>
          </div>
        </div>

      </div>
    </div>


    <!-- Marketing messaging and featurettes
    ================================================== -->
    <!-- Wrap the rest of the page in another container to center all the content. -->

    <div class="container marketing">

      <!-- START THE FEATURETTES -->
      
      

      <hr class="featurette-divider">

      <div class="row featurette">
        <div class="col-md-7">
          <h2 class="featurette-heading">Workshop <span class="text-muted">Program</span></h2><br>
           <!--<p class="lead">Location: Hilton Salon D</p>-->
          <p class="lead">Date: Friday February 10, 2017</p>
           <p class="lead">Time: 9:00am - 12:30pm</p>
        </div>
        <div class="col-md-5">
           <!--<img class="featurette-image img-responsive" data-src="holder.js/500x500/auto" alt="Generic placeholder image">-->
        </div>
      </div>
      
       <hr class="featurette-divider">
      

      <div class="row featurette">
        

        <div class="col-md-2">
          <h2 class="featurette-program-time">9:00</h2>
        </div>

        <div class="col-md-10">
          <!--<p>To Be Announced</p>-->
           <h2 class="featurette-program-title">Workshop introduction</h2>
          <h2 class="featurette-program-name">Tom Potok, Oak Ridge National Laboratory</h2>
           <!--<h2 class="featurette-program-name">Thomas Potok</h2>-->
        </div>
        
      </div>

      <hr class="featurette-divider">

      <div class="row featurette">

        <div class="col-md-2">
          <h2 class="featurette-program-time">9:05</h2>
        </div>

        <div class="col-md-10">
          <!--<p>To Be Announced</p>-->
          <h2 class="featurette-program-title">Invited talk</h2>
          <h2 class="featurette-program-name">Johanna McEntyre, Europe PMC</h2>
          <p class="program">Europe PMC is a database of abstracts and open access full text articles in the life sciences, covering all of PubMed and PMC. As a core part of the Europe PMC mission, we share this content as widely as possible to support the development of algorithms and text-mining tools based on this content. Recently, we developed a platform called SciLite that enables text miners to upload annotations and highlight them on articles, as a tool to assist readers in browsing, or to discover links to related data. In this presentation I will describe some of the ways that developers can consume textual data and publish results on Europe PMC, and how doing this could contribute to a more connected literature-data ecosystem for the life sciences.</p>
        </div>

      </div>

      <hr class="featurette-divider">

      <div class="row featurette">

        <div class="col-md-2">
          <h2 class="featurette-program-time">9:25</h2>
        </div>

        <div class="col-md-10">
          <h2 class="featurette-program-title">Effectively identifying users' research interests for scholarly reference management and discovery</h2>
          <h2 class="featurette-program-name">Marco Rossetti, Sa√∫l Vargas, Davide Magatti, Benjamin Pettit, Daniel Kershaw, Maya Hristakeva and Kris Jack</h2>
          <p class="program">Discovering users' interests is essential in order to help them explore resources in large digital repositories. In particular, correctly identifying users' interests is commonly a good approach for organising information and providing personalised recommendations. We consider the case of discovering users' research interests in Mendeley, a research platform for scholarly article management and discovery. Prior work in this area has considered approaches such as matrix factorisation and text-based topic modelling for inferring topics of interest in recommendation scenarios. These approaches present several problems, such as little or no interpretability of the inferred topics and difficulty handling similarities in vocabulary in different research disciplines. We present an effective solution for extracting coherent and interpretable research topics that leverages the reference management data in Mendeley in a three-step approach: 1) a topic model based on the interactions between users and articles rather than article content, 2) keyword extraction to label the topics using article titles and author-declared keywords and 3) identifying the research interests of users based on the articles that they have added to their libraries. An evaluation comprised of a research interest prediction task and a paper recommendation task shows the validity of our proposal in different research disciplines (clearly outperforming a text-based latent topic model) and provides further insights regarding the effects of number of latent topics in the model and the trade-off between recency and quantity of the users' libraries.</p>
        </div>

      </div>

      <hr class="featurette-divider">

      <div class="row featurette">

        <div class="col-md-2">
          <h2 class="featurette-program-time">9:40</h2>
        </div>

        <div class="col-md-10">
          <!--<p>To Be Announced</p>-->
          <h2 class="featurette-program-title">Scalable Algorithm for Probabilistic Overlapping Community Detection</h2>
          <h2 class="featurette-program-name">Kento Nozawa and Kei Wakabayashi</h2>
          <p class="program">In the data mining field, community detection, which decomposes a graph into multiple subgraphs, is one of the major techniques to analyze graph data.
            In recent years, the scalability of the community detection algorithm has been a crucial issue because of the growing size of real-world networks such as the co-author network and web graph.
            In this paper, we propose a scalable overlapping community detection method by using the stochastic variational Bayesian training of latent Dirichlet allocation (LDA) models, which predicts sets of neighbor nodes with a community mixture distribution.
            In the experiment, we show that the proposed method is much faster than previous methods and is capable of detecting communities even in a huge network that contains 60 million nodes and 1.8 billion edges.
            Furthermore, we compared different mini-batch sizes and the number of iterations in stochastic variational Bayesian inference to determine an empirical trade-off between efficiency and quality of overlapping community detection.</p>
        </div>

      </div>

      <hr class="featurette-divider">

      <div class="row featurette">

        <div class="col-md-2">
          <h2 class="featurette-program-time">9:55</h2>
        </div>

        <div class="col-md-10">
          <!--<p>To Be Announced</p>-->
          <h2 class="featurette-program-title">Building recommender systems for scholarly information</h2>
          <h2 class="featurette-program-name">Maya Hristakeva, Daniel Kershaw, Marco Rossetti, Petr Knoth, Benjamin Pettit, Saul Vargas and Kris Jack</h2>
          <p class="program">The depth and breadth of research now being published is overwhelming for an individual researcher to keep track of, let alone consume. Recommender systems have been developed to make it easier for researchers to discover relevant content. However, these have predominately taken the form of item-to-item recommendations using citation network features or text similarity features.
            This paper details how the Mendeley Suggest recommender system has been designed and developed. We show how implicit user feedback (based on activity data from the reference manager) and collaborative filtering (CF) are used to generate the recommendations for Mendeley Suggest. Because collaborative filtering suffers from the cold start problem (the inability to serve recommendations to new users), we developed additional recommendation methods based on user-defined attributes, such as discipline and research interests.
            Our off-line evaluation shows that where possible, recommendations based on collaborative filtering perform best, followed by recommendations based on recent activity. However, for cold users (for whom collaborative filtering was not possible) recommendations based on discipline performed best. Additionally, when we segmented users by career stages, we found that among senior academics, content-based recommendations from recent activity had comparable performance to collaborative filtering. This justifies our approach of developing a variety of recommendation methods, in order to serve a range of users across the academic spectrum.</p>
        </div>

      </div>

      <hr class="featurette-divider">

      <div class="row featurette">

        <div class="col-md-2">
          <h2 class="featurette-program-time">10:10</h2>
        </div>

        <div class="col-md-10">
          <!--<p>To Be Announced</p>-->
          <h2 class="featurette-program-title">Linking Mathematical Expressions to Wikipedia</h2>
          <h2 class="featurette-program-name">Giovanni Yoko Kristianto and Akiko Aizawa</h2>
          <p class="program">This paper addresses the challenge of determining the identity of mathematical expressions in documents by linking these expressions to their corresponding Wikipedia articles.
            Math expressions are frequently used to describe important concepts in scientific documents; however, particularly in the case of famous or well-established equations, they are often minimally explained within the documents themselves.
            Linking to Wikipedia allows readers to obtain additional explanation of these math expressions.
            This paper proposes a learning-based approach to solve this challenge using common features, such as math and text similarities, as well as the importance of the math expression within the document.
            Further, we develop a dataset that allowed us to train and test our proposed approach.
            Experimental results show that our learning-based approach achieves a precision of 83.40%, compared with 6.22% for the baseline method (a straightforward application of Math IR).</p>
        </div>

      </div>

      <hr class="featurette-divider">

      <div class="row featurette">

        <div class="col-md-2">
          <h2 class="featurette-program-time">10:25</h2>
        </div>

        <div class="col-md-10">
          <!--<p>To Be Announced</p>-->
          <h2 class="featurette-program-title">Break</h2>
        </div>

      </div>

      <hr class="featurette-divider">

      <div class="row featurette">

        <div class="col-md-2">
          <h2 class="featurette-program-time">10:55</h2>
        </div>

        <div class="col-md-10">
          <!--<p>To Be Announced</p>-->
          <h2 class="featurette-program-title">Invited talk</h2>
          <h2 class="featurette-program-name">Mads Rydahl, UNSILO</h2>
          <p class="program">Mads will present the UNSILO Concept Extraction pipeline, and describe some of the recent products UNSILO has built for the Scientific Publishing industry, and outline the future direction of Scientific Text Intelligence.</p>
        </div>

      </div>

      <hr class="featurette-divider">

      <div class="row featurette">

        <div class="col-md-2">
          <h2 class="featurette-program-time">11:10</h2>
        </div>

        <div class="col-md-10">
          <!--<p>To Be Announced</p>-->
          <h2 class="featurette-program-title">Predicting MeSH Beyond MEDLINE</h2>
          <h2 class="featurette-program-name">Adam Kehoe, Vetle Torvik, Matthew Ross and Neil Smalheiser</h2>
          <p class="program">Medical subject headings (MeSH) are a Ô¨Çexible and useful tool for describing biomedical concepts. Here, we present MeSHier, a tool for assigning MeSH terms to biomedical documents based on abstract similarity and references to MEDLINE records. When applied to PubMedCentral papers, NIH grants, and USPTO patents we Ô¨Ånd that these two sources of information produce largely disjoint sets of related MEDLINE records, albeit with some overlap in MeSH. When combined they provide an enriched topical annotation that would not have been possible with either alone. MeSHier is available as a demo tool that can take as input IDs of PubMed papers, USPTO patents, and NIH grants: http://abel.lis.illinois.edu/cgi-bin/meshier/search.py </p>
        </div>

      </div>

      <hr class="featurette-divider">

      <div class="row featurette">

        <div class="col-md-2">
          <h2 class="featurette-program-time">11:25</h2>
        </div>

        <div class="col-md-10">
          <!--<p>To Be Announced</p>-->
          <h2 class="featurette-program-title">ScholarBase: Towards a Cross-Domain Knowledgebase for Linked Scholarly Data</h2>
          <h2 class="featurette-program-name">Mahmoud Elbattah</h2>
          <p class="program">Over the last years, Linked Data has gained a significant momentum through various initiatives embraced by academia and industry as well. In this paper, we introduce ScholarBase, a research project in progress that is aimed to serve as a Linked Data repository for cross-domain scholarly data. ScholarBase can be conceived as a knowledgebase that weaves links among scholars, institutions, research areas, publications, and geographical locations in a Linked Data fashion. Initially, the primary source of data stems from Google Scholar, specifically the profile pages of scholars. Subsequently, the collected dataset is transformed into a semantic-based format (i.e. RDF model). The semantified dataset will enable a machine-readable expression of entity relationships, and can in turn be linked to external knowledge bases (e.g. DBpedia). Through the paper, we discuss the architecture and implementation of the project. ScholarBase can play an important role in the Linked Data web by opening extended opportunities for interesting applications, and data exploration of scholarly data.</p>
        </div>

      </div>

      <hr class="featurette-divider">

      <div class="row featurette">

        <div class="col-md-2">
          <h2 class="featurette-program-time">11:40</h2>
        </div>

        <div class="col-md-10">
          <!--<p>To Be Announced</p>-->
          <h2 class="featurette-program-title">Describing Data Processing Pipelines in Scientific Publications for Big Data Injection</h2>
          <h2 class="featurette-program-name">Sepideh Mesbah, Alessandro Bozzon, Christoph Lofi and Geert-Jan Houben</h2>
          <p class="program">The rise of Big Data analytics has been a disruptive game changer for many application domains, allowing the integration into domain-specific applications and systems of insights and knowledge extracted from external big data sets. The effective ``injection'' of external Big Data demands an understanding of the properties of available data sets, and expertise on the available and most suitable methods for data collection, enrichment and analysis. A prominent knowledge source is scientific literature, where data processing pipelines are described, discussed, and evaluated. Such knowledge is however not readily accessible, due to its distributed and unstructured nature. In this paper, we propose a novel ontology aimed at modeling properties of data processing pipelines, and their related artifacts, as described in scientific publications. The ontology is the result of a requirement analysis that involved experts from both academia and industry. We showcase the effectiveness of our ontology by manually applying it to a collection of Big Data related publications, thus paving the way for future work on more informed Big Data injection workflows.</p>
        </div>

      </div>

      <hr class="featurette-divider">

      <div class="row featurette">

        <div class="col-md-2">
          <h2 class="featurette-program-time">11:55</h2>
        </div>

        <div class="col-md-10">
          <!--<p>To Be Announced</p>-->
          <h2 class="featurette-program-title">Citations and readership are poor indicators of research excellence: Introducing TrueID, a new dataset for validating research evaluation metrics</h2>
          <h2 class="featurette-program-name">Drahomira Herrmannova, Robert Patton, Petr Knoth and Christopher Stahl</h2>
          <p class="program">In this paper we show that citation counts and Mendeley readership are poor indicators of research excellence. Our experimental design builds on the assumption that a good evaluation metric should be able to distinguish publications that have changed a research field from those that have not. The experiment has been conducted on a new dataset for bibliometric research which we call True Impact Dataset (TrueID). TrueID is a collection of research publications of two types -- research papers which are considered seminal work in their area and papers which provide a survey (a literature review) of a research area. The dataset also contains related metadata, which include DOIs, titles, authors and abstracts. We describe how the dataset was built and provide overview statistics of the dataset. We propose to use the dataset for validating research evaluation metrics. By using this data, we show that widely used research metrics only poorly distinguish excellent research.</p>
        </div>

      </div>

      <hr class="featurette-divider">

      <div class="row featurette">

        <div class="col-md-2">
          <h2 class="featurette-program-time">12:10</h2>
        </div>

        <div class="col-md-10">
          <!--<p>To Be Announced</p>-->
          <h2 class="featurette-program-title">Invited talk</h2>
          <h2 class="featurette-program-name">Kiera McNeice, FutureTDM</h2>
          <p class="program">FutureTDM has spent the last 18 months engaging with stakeholders in all aspects of the text and data mining value chain, developing an understanding of the challenges and opportunities these technologies offer to researchers and industry across Europe. In the final six months of the project we will be developing concrete guidelines for stakeholders in key areas, to support greater adoption of TDM in Europe. In this talk we will introduce some of the guidelines we propose to deliver, addressing issues such as minimising legal risk in TDM, and encouraging universities to support TDM across a broad range of disciplines.</p>
        </div>

      </div>

      <hr class="featurette-divider">

      <div class="row featurette">

        <div class="col-md-2">
          <h2 class="featurette-program-time">12:25</h2>
        </div>

        <div class="col-md-10">
          <!--<p>To Be Announced</p>-->
          <h2 class="featurette-program-title">Closing</h2>
          <!--<h2 class="featurette-program-name">Thomas Potok</h2>-->
        </div>

      </div>

      <hr class="featurette-divider">

      <div class="row featurette">

        <div class="col-md-2">
          <h2 class="featurette-program-time">12:30</h2>
        </div>

        <div class="col-md-10">
          <!--<p>To Be Announced</p>-->
          <h2 class="featurette-program-title">Lunch</h2>
        </div>

      </div>
      
      <!--<hr class="featurette-divider">-->
      

      <!--<div class="row featurette">-->
        
        
        <!--<div class="col-md-7">-->
        <!--  <h2 class="lead">Keynote: Bryan Catanzaro<br>-->
        <!--  2:00pm - 3:00pm</h2>-->
        <!--  <p class="lead"><span class="text-muted">Baidu Research Silicon Valley Artificial Intelligence Laboratory</span></p>-->
        <!--  <p>During the past few years, deep learning has made incredible progress towards solving many previously difficult Artificial Intelligence (AI) tasks.  Although the techniques behind deep learning have been studied for decades, they rely on large datasets and large computational resources, and so have only recently become practical for many problems.  Training deep neural networks is very computationally intensive: training one model takes tens of exaflops of work, and so HPC techniques are key to creating these models.  As in other fields, progress in AI is iterative, building on previous ideas.  This means that the turnaround time in training models is a key bottleneck to progress in AI‚Äîthe quicker an idea can be realized as a trainable model, train it on a large dataset, and test it, the quicker that ways can be found of improving the models.  In this talk, Catanzaro will discuss the key insights that make deep learning work for many problems, describe the training problem, and detail the use of standard HPC techniques that allow him to rapidly iterate on his models.  He will explain how HPC ideas are becoming increasingly central to progress in AI and will also show several examples of how deep learning is helping solve difficult AI problems.</p>-->
        <!--</div>-->
        
        <!--<div class="col-md-5">-->
          <!--<img class="featurette-image img-responsive" src="bio_images/Catanzaro.jpg" alt="Bryan Catanzaro">-->
        <!--</div>-->
        
      <!--</div>-->
      
      <!--<hr class="featurette-divider">-->
      <!--<div class="row featurette">-->
        
        
        <!--<div class="col-md-7">-->
        <!--  <h2 class="lead">Coffee Break<br>-->
        <!--  3:00pm - 3:30pm</h2>-->
        <!--</div>-->
      <!--</div>-->

      <!--<hr class="featurette-divider">-->

      <!--<div class="row featurette">-->
      <!--  <div class="col-md-5">-->
      <!--    <img class="featurette-image img-responsive" data-src="holder.js/500x500/auto" alt="Generic placeholder image">-->
      <!--  </div>-->
        <!-- 
        <div class="col-md-7">
          <h2 class="lead">Asynchronous Parallel Stochastic Gradient Descent - A Numeric Core for Scalable Distributed Machine Learning Algorithms<br>
          3:30pm - 3:55pm</h2>
          <p class="lead"><span class="text-muted">Janis Keuper and Franz-Josef Pfreundt</h2></span></p>
          <p>The implementation of a vast majority of machine learning (ML) algorithms boils down
to solving a numerical optimization problem. In this context, Stochastic
Gradient Descent (SGD) methods have long proven to provide good results, both
in terms of convergence and accuracy. Recently, several parallelization approaches
have been proposed in order to scale SGD to solve very large ML problems.
At their core, most of these approaches are following a MapReduce scheme.
This paper presents a novel parallel updating algorithm for SGD, which utilizes
the asynchronous single-sided communication paradigm.
Compared to existing methods, Asynchronous Parallel Stochastic Gradient Descent (ASGD) provides faster convergence,
at linear scalability and stable accuracy.</p>
          <p><a href=presentations/1-Janis.pdf>[Presentation]</a> <a href=http://dx.doi.org/10.1145/2834892.2834893>[Paper]</a></p>
        </div>
        -->
      <!--</div>-->
      
      <!--<hr class="featurette-divider">-->

      <!--<div class="row featurette">-->
      <!--  <div class="col-md-5">-->
      <!--    <img class="featurette-image img-responsive" data-src="holder.js/500x500/auto" alt="Generic placeholder image">-->
      <!--  </div>-->
        <!-- 
        <div class="col-md-7">
          <h2 class="lead">HPDBSCAN ‚Äì Highly Parallel DBSCAN<br>
          3:55pm - 4:20pm</h2>
          <p class="lead"><span class="text-muted">Markus G√∂tz, Christian Bodenstein and Morris Riedel</h2></span></p>
          <p>Clustering algorithms in the field of data-mining are used
to aggregate similar objects into common groups. One of
the best-known of these algorithms is called DBSCAN. Its
distinct design enables the search for an apriori unknown
number of arbitrarily shaped clusters, and at the same time
allows to filter out noise. Due to its sequential formulation, the parallelization of DBSCAN renders a challenge. In
this paper we present a new parallel approach which we call
HPDBSCAN. It employs three major techniques in order
to break the sequentiality, empower workload-balancing as
well as speed up neighborhood searches in distributed parallel processing environments i) a computation split heuristic
for domain decomposition, ii) a data index preprocessing
step and iii) a rule-based cluster merging scheme.
As a proof-of-concept we implemented HPDBSCAN as an
OpenMP/MPI hybrid application. Using real-world data
sets, such as a point cloud from the old town of Bremen,
Germany, we demonstrate that our implementation is able
to achieve a significant speed-up and scale-up in common
HPC setups. Moreover, we compare our approach with previous attempts to parallelize DBSCAN showing an order of
magnitude improvement in terms of computation time and
memory consumption.</p>
          <p><a href=presentations/2-Markus.pdf>[Presentation]</a> <a href=http://dx.doi.org/10.1145/2834892.2834894>[Paper]</a></p>
        </div>
        -->
      <!--</div>-->
      
      <!--<hr class="featurette-divider">-->

      <!--<div class="row featurette">-->
      <!--  <div class="col-md-5">-->
      <!--    <img class="featurette-image img-responsive" data-src="holder.js/500x500/auto" alt="Generic placeholder image">-->
      <!--  </div>-->
        <!-- 
        <div class="col-md-7">
          <h2 class="lead">LBANN: Livermore Big Artificial Neural Network HPC Toolkit<br>
          4:20pm - 4:45</h2>
          <p class="lead"><span class="text-muted">Brian Van Essen, Hyojin Kim, Roger Pearce, Kofi Boakye and Barry Chen</span></p>
          <p>Recent successes of deep learning have been largely driven by the ability to train large models on vast amounts of data. We believe that High Performance Computing (HPC) will play an increasingly important role in helping deep learning achieve the next level of innovation fueled by neural network models that are orders of magnitude larger and trained on commensurately more training data. We are targeting the unique capabilities of both current and upcoming HPC sys- tems to train massive neural networks and are developing the Livermore Big Artificial Neural Network (LBANN) toolkit to exploit both model and data parallelism optimized for large scale HPC resources. This paper presents our prelimi- nary results in scaling the size of model that can be trained with the LBANN toolkit.</p>
          <p><a href=presentations/3-Brian.pdf>[Presentation]</a> <a href=http://dx.doi.org/10.1145/2834892.2834897>[Paper]</a></p>
        </div>
        -->
      <!--</div>-->
      
      <!--<hr class="featurette-divider">-->

      <!--<div class="row featurette">-->
      <!--  <div class="col-md-5">-->
      <!--    <img class="featurette-image img-responsive" data-src="holder.js/500x500/auto" alt="Generic placeholder image">-->
      <!--  </div>-->
        <!-- 
        <div class="col-md-7">
          <h2 class="lead">Optimizing Deep Learning Hyper-Parameters Through an Evolutionary Algorithm<br>
          4:45pm - 5:10pm</h2>
          <p class="lead"><span class="text-muted">Steven Young, Derek Rose, Thomas Karnowski, Seung-Hwan Lim and Robert Patton</h2></span></p>
          <p>There has been a recent surge of success in utilizing Deep Learning (DL) in imaging and speech applications for its relatively automatic feature generation and, in particular for convolutional neural networks (CNNs), high accuracy classification abilities. While these models learn their parameters through data-driven methods, model selection (as architecture construction) through hyper-parameter choices remains a tedious and highly intuition driven task. To address this, Multi-node Evolutionary Neural Networks for Deep Learning (MENNDL) is proposed as a method for automating network selection on computational clusters through hyper-parameter optimization performed via genetic algorithms.</p>
          <p><a href=presentations/4-Steven.pdf>[Presentation]</a> <a href=http://dx.doi.org/10.1145/2834892.2834896>[Paper]</a></p>
        </div>
	-->
        
      <!--</div>-->
	
      <!--<hr class="featurette-divider">-->

      <!--<div class="row featurette">-->
        <!--
        <div class="col-md-5">
          <img class="featurette-image img-responsive" data-src="holder.js/500x500/auto" alt="Generic placeholder image">
        </div>
        -->
        
        
      <!--</div>-->
      
      <!--<hr class="featurette-divider">-->
      
      
	
	  <!--
      <hr class="featurette-divider">
Program
	
      <div class="row featurette">
        <div class="col-md-7">
          <h2 class="featurette-heading">And lastly, this one. <span class="text-muted">Checkmate.</span></h2>
          <p class="lead">Donec ullamcorper nulla non metus auctor fringilla. Vestibulum id ligula porta felis euismod semper. Praesent commodo cursus magna, vel scelerisque nisl consectetur. Fusce dapibus, tellus ac cursus commodo.</p>
        </div>
        <div class="col-md-5">
          <img class="featurette-image img-responsive" data-src="holder.js/500x500/auto" alt="Generic placeholder image">
        </div>
      </div>

      <hr class="featurette-divider">
      -->

      <!-- /END THE FEATURETTES -->

      <br>
      <br>
      <br>
      <br>


      <!-- FOOTER -->
      <footer>
      	<div style="width: 100%;overflow:auto;">
          <div style="float:left; width: 50%">

            <a name="contact"></a>
            <p><b>Contact:  Robert M. Patton</b>, pattonrm "at" ornl.gov</p>
            <p>&copy; 2016 Oak Ridge National Laboratory</p>
          </div>
           
          <!--<div style="float:right;">-->
            <!--<p>In cooperation with</p>-->
            <!--<a class="brand" href="https://www.ornl.gov/"> <img src="images/ornl_logo.png" alt="Oak Ridge National Laboratory"></a>-->
          <!--</div>-->
          
        </div>
        <p class="pull-right"><a href="#">Back to top</a></p>
      </footer>

    </div><!-- /.container -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script src="./dist/js/bootstrap.min.js"></script>
    <script src="./assets/js/docs.min.js"></script>
  </body>
</html>
